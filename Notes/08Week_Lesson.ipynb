{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA \n",
    "\n",
    "Dimensional reduction. The problem to solve is this: find a lower dimensional representation of the data that contains as much as possible of the variation of the data. \n",
    "\n",
    "For example, a rotation: point $(x_{1}, x_{2}) \\rightarrow (y_{1},y_{2})$ to $(x_{1}, x_{2}) \\rightarrow (y_{1},0)$ where the second set of points is a lower dimensional state, and assuming $\\lvert y_{2}\\rvert << \\lvert y_{1} \\rvert$.\n",
    "\n",
    "* 1) demean the data: remove the mean (or center the data), so $x_{1} = x_{1,origin} - \\overline x_{1}$, and $x_{2} = x_{2,orig} - \\overline x_{2}$ and scale values appropriately. \n",
    "\n",
    "* 2) find covariance matrix: we are looking for a linear transformation between $x_{1}....x_{p}$ by some matrix of $\\phi_{11}...\\phi_{pp}$ to get to some $y_{1}...y_{p}$. The matrix of $\\phi$ values is normalized st $\\phi_{11}^{2} + \\phi_{12}^{2} + ... \\phi_{1p}^{2} = 1$, where p is the number of features/attributes. \n",
    "\n",
    "* 3) find eigenvalues and eigenvectors of covariance matrix. \n",
    "\n",
    "* 4) sort the eigenvalues from largest to smallest. \n",
    "\n",
    "* 5) take the M eigenvectors corresponding to the M largest eigenvalues (M < P).\n",
    "\n",
    "* 6) transform the data into lower dimensional space (M-dimensional space). \n",
    "\n",
    "The first principal component is the line that is closest  to the n-data points. The first + second principal components define the plane which is the closest to the n-data points. \n",
    "\n",
    "$\\overleftrightarrow X$ is some matrix ($x_{11}...x_{NP}$) of size N x P ,where N is number of data points, and p is dimension of each point, where $P < N$. This represents our input data. The first step then is to find and remove the mean so that the mean of each column in the matrix is zero. If not all objects in the matrix have the same units, you will want to scale the variables to have a standard deviation of one. How many principal components to use? The number should be much less than P, since the goal is to simplify the problem. One can look at this more quantitatively by seeing how much of the variance in the data is described by different numbers of components. \n",
    "\n",
    "We want to calculate $\\overleftrightarrow X^{T} \\overleftrightarrow X$. That will give us essentially $N \\times \\overleftrightarrow S$, where S is the convariance matrix (filled with expectation values of combination of diff variables, e.g. $<xx> = \\frac{1}{N}[x_{1}y_{1} + ... x_{N}y_{N}]$) of size PxP.  \n",
    "\n",
    "Next we want to find eigenvalues and eigenvectors of covariance matrix (can be done with something like numpy.linalg). Then sort eigenvalues, and take M eigenvectors corresponding to largest M eigenvalues, which we then use to transform data into lower M-dimensional space. \n",
    "\n",
    "Scree plot: plot number on x-axis and eigenvalues at y-axis and see where flattening point is to decide number of principal components. Another way to choose number of components: \n",
    "\n",
    "$ R^{2} = \\frac{\\sum_{i=1}^{q} \\lambda_{i}}{\\sum_{i=1}^{p} \\lambda_{i}}$, where p is total number of parameters and $\\lambda$ are eigenvalues. On the top we sum only until q to calculate $R^{2}$ the fraction of original variance. The rule of thumb is to keep as many components as are required to get $R^{2} = 0.8$ \n",
    "\n",
    "Next time: singular value decomposition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
